{
  "hash": "fa9e62e7167c39c710ec08b0a1365966",
  "result": {
    "markdown": "---\ntitle: \"Regularização de Modelos\"\nauthor: \"Ricardo Accioly\"\ndate: \"2022-10-04\"\noutput:\n html_document:\n    toc: yes\n    code_download: yes\n---\n\n\n## Regularização de modelos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# parametros para imagens\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.73,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"90%\"\n)\n```\n:::\n\n\n## Carregando Bibliotecas\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(glmnet)\ndata(Boston)\n```\n:::\n\n\n## Carregando os dados\n\nVamos utilizar neste exemplo os dados contidos na biblioteca MASS. A base de dados Boston tem 506 de valores preços medianos de casas na região de Boston com 13 outras variáveis explicativas (potencialmente). Vamos explorar os dados e ajustar modelos com penalização o Ridge e o LASSO e depois vamos comparar com os mínimos quadrados.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Boston)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat\n1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98\n2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14\n3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03\n4 0.03237  0  2.18    0 0.458 6.998 45.8 6.0622   3 222    18.7 394.63  2.94\n5 0.06905  0  2.18    0 0.458 7.147 54.2 6.0622   3 222    18.7 396.90  5.33\n6 0.02985  0  2.18    0 0.458 6.430 58.7 6.0622   3 222    18.7 394.12  5.21\n  medv\n1 24.0\n2 21.6\n3 34.7\n4 33.4\n5 36.2\n6 28.7\n```\n:::\n\n```{.r .cell-code}\nsummary(Boston)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      crim                zn             indus            chas        \n Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  \n 1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  \n Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  \n Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  \n 3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  \n Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  \n      nox               rm             age              dis        \n Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  \n 1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  \n Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  \n Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  \n 3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  \n Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  \n      rad              tax           ptratio          black       \n Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  \n 1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  \n Median : 5.000   Median :330.0   Median :19.05   Median :391.44  \n Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  \n 3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  \n Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  \n     lstat            medv      \n Min.   : 1.73   Min.   : 5.00  \n 1st Qu.: 6.95   1st Qu.:17.02  \n Median :11.36   Median :21.20  \n Mean   :12.65   Mean   :22.53  \n 3rd Qu.:16.95   3rd Qu.:25.00  \n Max.   :37.97   Max.   :50.00  \n```\n:::\n:::\n\n\nObservamos acima que todas as variáveis são quantitativas e que não há necessidade de transformações.\n\n## Significado das variáveis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boston Database\n# \n#1) crim - taxa de criminalidade per capita por cidade.\n# \n#2) zn - proporção de terrenos residenciais para lotes acima de 25,000 sq.ft.\n# \n#3) indus - proporção de negócios não comerciais por acres e por cidade.\n# \n#4) chas - variável dummy do Rio Charles(= 1 se próximo do rio; 0 de outra forma).\n# \n#5) nox - concentração de óxido de nitrogênio (partes por 10 milhões).\n# \n#6) rm - número médio de quartos por habitação\n# \n#7) age - proporção da unidade ocupadas pelos proprietários construídas antes 1940.\n# \n#8) dis - média ponderada das distâncias dos 5 pontos de emprego em Boston.\n# \n#9) rad - indice de acessibilidade das avenidas radiais.\n# \n#10) tax - valor cheio da taxa de propriedade por $10,000.\n# \n#11) ptratio - razão aluno-professor por cidade.\n# \n#12) black - 1000(Bk−0.63)21000(Bk−0.63)2 proporção de negros por cidade.\n# \n#13) lstat - percentual de baixo status da população.\n# \n#14) medv - valor mediano das cas ocupadas pelos proprietário em $1000s. (Var. Resposta)\n```\n:::\n\n\n## Conjunto de treino e de teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: lattice\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'caret'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n:::\n\n```{.r .cell-code}\nset.seed(21)\ny <- Boston$medv\nindice_teste <- createDataPartition(y, times = 1, p = 0.1, list = FALSE)\n\nconj_treino <- Boston %>% slice(-indice_teste)\nconj_teste <- Boston %>% slice(indice_teste)\nstr(conj_treino)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t454 obs. of  14 variables:\n $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...\n $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...\n $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...\n $ rm     : num  6.58 6.42 7.18 7 7.15 ...\n $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 100 94.3 82.9 39 ...\n $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...\n $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...\n $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...\n $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...\n $ black  : num  397 397 393 395 397 ...\n $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...\n $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 16.5 15 18.9 21.7 ...\n```\n:::\n\n```{.r .cell-code}\nstr(conj_teste)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t52 obs. of  14 variables:\n $ crim   : num  0.0883 0.1446 0.17 1.2518 0.773 ...\n $ zn     : num  12.5 12.5 12.5 0 0 0 0 0 85 0 ...\n $ indus  : num  7.87 7.87 7.87 8.14 8.14 ...\n $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...\n $ nox    : num  0.524 0.524 0.524 0.538 0.538 0.499 0.448 0.448 0.41 0.437 ...\n $ rm     : num  6.01 6.17 6 5.57 6.5 ...\n $ age    : num  66.6 96.1 85.9 98.1 94.4 41.5 6.6 95.3 35.7 53.7 ...\n $ dis    : num  5.56 5.95 6.59 3.8 4.45 ...\n $ rad    : int  5 5 5 4 4 5 3 3 2 5 ...\n $ tax    : num  311 311 311 307 307 279 233 233 313 398 ...\n $ ptratio: num  15.2 15.2 15.2 21 21 19.2 17.9 17.9 17.3 18.7 ...\n $ black  : num  396 397 387 377 388 ...\n $ lstat  : num  12.4 19.1 17.1 21 12.8 ...\n $ medv   : num  22.9 27.1 18.9 13.6 18.4 21 25.3 14.4 24.7 21.2 ...\n```\n:::\n:::\n\n\n## Métodos de Regularização\n\nO pacote glmnet não usa a linguagem de formula, em particular nós devemos passar $x$ como uma matriz e $y$ como um vetor, pois não se usa a sintaxe $y \\sim x$. Com isso será necessário ajustar x e y. A função model.matrix() é particularmente útil para criar x; não só produz uma matriz correspondente as variáveis explicativas, **mas também transforma automaticamente quaisquer variáveis qualitativas em variáveis dummy. Esta última propriedade é importante porque o glmnet() só pode tomar insumos numéricos e quantitativos.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx_treino <- model.matrix(medv ~ . , data = conj_treino)[, -1]\ny_treino <- conj_treino$medv\n\nx_teste <- model.matrix(medv ~ . , data = conj_teste)[, -1]\ny_teste = conj_teste$medv\n```\n:::\n\n\n## Regressão Ridge\n\nPrimeiro vamos ajustar um modelo de regressão Ridge. Isso é conseguido chamando `glmnet()` com `alpha=0`, se `alpha=1` então `glmnet()` ajusta um lasso.(veja o arquivo de ajuda).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Estabelecendo um grid de valores para lambda\ngrid <- 10^seq(-2, 10, length = 100)\najusreg.ridge <- glmnet(x_treino, y_treino, alpha=0, lambda = grid)\n```\n:::\n\n\nPor padrão, a função `glmnet()` executa a regressão ridge automaticamente selecionando a faixa de valores de $\\lambda$. No entanto, aqui nós escolhemos implementar usando uma grade de valores que variam de $\\lambda = 10^{-2}$ a $\\lambda = 10^{10}$, cobrindo toda a gama de cenários do modelo nulo contendo apenas o coeficiente linear até o ajuste dos mínimos quadrados.\n\nTambém podemos calcular o modelo para um valor particular de $\\lambda$ que não é um dos valores de grade. Observe que, por padrão, a função `glmnet()` padroniza as variáveis para que elas estejam na mesma escala. **Esta padronização é muito importante no caso da regressão Ridge, pois ela é afetada pela mudança de escala das variáveis explicativas.**\n\nAssociado a cada valor de $\\lambda$ existe um vetor de coeficientes de regressão de ridge, que é armazenado em uma matriz que pode ser acessada por 'coef()'. Neste caso, é uma matriz $14 \\times 100$, com 14 linhas (uma para cada preditor, mais uma para o coeficiente linear) e 100 colunas (uma para cada valor de $\\lambda$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(coef(ajusreg.ridge))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  14 100\n```\n:::\n\n```{.r .cell-code}\nplot(ajusreg.ridge, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/r1-1.png){width=90%}\n:::\n:::\n\n\nQuando $\\lambda$ é grande o esperado é que os coeficentes sejam pequenos e quando $\\lambda$ é pequeno os coeficientes assumem valores maiores.\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.ridge$lambda[1] # Mostra primeiro valor de lambda\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1e+10\n```\n:::\n\n```{.r .cell-code}\ncoef(ajusreg.ridge)[,1] # Mostra os coeficientes associados com o primeiro valor\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept)          crim            zn         indus          chas \n 2.250903e+01 -4.310869e-10  1.236696e-10 -5.781786e-10  6.671751e-09 \n          nox            rm           age           dis           rad \n-3.109566e-08  8.544185e-09 -1.096866e-10  9.831217e-10 -3.592692e-10 \n          tax       ptratio         black         lstat \n-2.291059e-11 -1.978388e-09  3.093734e-11 -8.714477e-10 \n```\n:::\n\n```{.r .cell-code}\najusreg.ridge$lambda[100] # Mostra centésimo valor de lambda\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01\n```\n:::\n\n```{.r .cell-code}\ncoef(ajusreg.ridge)[,100] # Mostra os coeficientes associados com o centésimo valor\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept)          crim            zn         indus          chas \n 32.526960193  -0.077860032   0.048164328   0.037384134   3.185485477 \n          nox            rm           age           dis           rad \n-16.609513650   4.033526898  -0.004052455  -1.496881369   0.283749613 \n          tax       ptratio         black         lstat \n -0.011488943  -0.897004892   0.011580532  -0.523709612 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plotmo)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: Formula\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: plotrix\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nCarregando pacotes exigidos: TeachingDemos\n```\n:::\n\n```{.r .cell-code}\nplot_glmnet(ajusreg.ridge)\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/r3-1.png){width=90%}\n:::\n:::\n\n\n## Cross-Validation no Ridge\n\nNós podemos usar o k-fold cross validation para identificar o melhor valor de $\\lambda$\n\nA biblioteca glmnet já tem internamente uma função para uso do crosss validation. O default são 10 envelopes de dados `nfold=10`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(21)\nridge_cv <- cv.glmnet(x_treino,y_treino, alpha=0) ## por padrão k=10\nplot(ridge_cv)\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/r4-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nm_lamb <- ridge_cv$lambda.min  # Seleciona o lambda que minimiza o MSE (EQM) de treino\nm_lamb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6814688\n```\n:::\n\n```{.r .cell-code}\nlog(m_lamb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.3835048\n```\n:::\n\n```{.r .cell-code}\ncoef(ridge_cv, s=m_lamb)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n14 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  24.882963482\ncrim         -0.061645846\nzn            0.033330267\nindus        -0.019698101\nchas          3.349639088\nnox         -11.297569439\nrm            4.206934065\nage          -0.006409007\ndis          -1.128065181\nrad           0.147695078\ntax          -0.005476850\nptratio      -0.818789882\nblack         0.011174291\nlstat        -0.471789754\n```\n:::\n:::\n\n\n## Avaliando com conjunto de teste\n\nEm seguida avaliamos seu MSE no conjunto de teste, usando $\\lambda$ = m_lamb. Observe o uso da função 'predict()': desta vez temos previsões para um conjunto de teste, com o argumento `newx`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.ridge2 <- glmnet(x_treino, y_treino, alpha=0, lambda = m_lamb)\ny_prev <- predict(ajusreg.ridge2, s = m_lamb, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.735108\n```\n:::\n:::\n\n\n## LASSO\n\nPrimeiro ajustamos com todos os dados como no caso do Ridge\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.lasso <- glmnet(x_treino,y_treino, alpha = 1)\nplot(ajusreg.lasso, xvar=\"lambda\", label=TRUE) # Representando os coeficientes\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/LASSO-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nplot_glmnet(ajusreg.lasso)\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/LASSO-2.png){width=90%}\n:::\n:::\n\n\n## Validação Cruzada no LASSO\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_cv <- cv.glmnet(x_treino,y_treino, alpha = 1)\nplot(lasso_cv)\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/Lasso2-1.png){width=90%}\n:::\n\n```{.r .cell-code}\nm_lamb1 <- lasso_cv$lambda.min  # Seleciona o lambda que minimiza o MSE de treino\nm_lamb1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.03391686\n```\n:::\n\n```{.r .cell-code}\nlog(m_lamb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3.383843\n```\n:::\n\n```{.r .cell-code}\ncoef(lasso_cv, s=m_lamb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n14 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  30.230724816\ncrim         -0.065462135\nzn            0.042187567\nindus         .          \nchas          3.162640335\nnox         -14.960411177\nrm            4.074692139\nage          -0.001578690\ndis          -1.398373691\nrad           0.222328784\ntax          -0.008398104\nptratio      -0.871671168\nblack         0.011260630\nlstat        -0.524311000\n```\n:::\n:::\n\n\n## Avaliando com conjunto de teste\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.lasso2 <- glmnet(x_treino, y_treino, alpha=1, lambda = m_lamb1)\ny_prev <- predict(ajusreg.lasso2, s = m_lamb1, newx = x_teste)\n# Metricas de desempenho\nsqrt(mean((y_prev - y_teste)^2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.712517\n```\n:::\n:::\n\n\n## Comparando com a seleção de modelos usando o Cp\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(leaps)\najusreg.comp <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg <- summary(ajusreg.comp)\n## Os modelos vão ser escolhidos com base no menor Cp\nplot(sumario.reg$cp,xlab=\"Número de Variáveis\",ylab=\"Cp\")\nwhich.min(sumario.reg$cp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 11\n```\n:::\n\n```{.r .cell-code}\npoints(9,sumario.reg$cp[9],pch=20,col=\"red\")\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/outro-1.png){width=90%}\n:::\n:::\n\n\n## Ajustando no lm() e vendo o erro no conjunto de teste\n\nObservando so resultados de erro vemos que tanto a regressão Ridge como o LASSO apresentaram valores de erro maiores que o modelo definido através da melhor seleção de modelos (best subset regression). Aqui usamos o Cp de Mallows como critério de deleção de variáveis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(ajusreg.comp,9) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept)           zn         chas          nox           rm          dis \n 29.80134106   0.03671717   3.46191054 -18.18784987   4.20337641  -1.39639924 \n         rad      ptratio        black        lstat \n  0.08670126  -0.94121090   0.01281630  -0.54794389 \n```\n:::\n\n```{.r .cell-code}\noutro_mod <- lm(medv ~ zn + chas + nox + rm + age + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = medv ~ zn + chas + nox + rm + age + dis + ptratio + \n    black + lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.2019  -2.8156  -0.5545   1.6396  27.8963 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  25.803185   5.257556   4.908 1.30e-06 ***\nzn            0.041284   0.014228   2.902 0.003896 ** \nchas          3.569931   0.958875   3.723 0.000222 ***\nnox         -14.554458   3.592818  -4.051 6.02e-05 ***\nrm            4.383560   0.446194   9.824  < 2e-16 ***\nage          -0.008097   0.014265  -0.568 0.570563    \ndis          -1.459967   0.211252  -6.911 1.68e-11 ***\nptratio      -0.797677   0.122747  -6.499 2.18e-10 ***\nblack         0.011413   0.002713   4.206 3.14e-05 ***\nlstat        -0.527402   0.053273  -9.900  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.841 on 444 degrees of freedom\nMultiple R-squared:  0.7315,\tAdjusted R-squared:  0.7261 \nF-statistic: 134.4 on 9 and 444 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsqrt(mean((conj_teste$medv - predict(outro_mod, conj_teste)) ^ 2)) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.041515\n```\n:::\n:::\n\n\n## E o BIC?\n\nE se escolhessemos o BIC como critério de seleção de variáveis explicativas? Neste caso os resultados foram iguais ao Cp. Entretanto, dá para perceber que o BIC apresentou uma certa estabilidade entre 7 e 9 variáveis. Se quisermos ter um modelo mais enxuto poderiamos optar por 7 variáveis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\najusreg.comp1 <- regsubsets(medv ~ ., data=conj_treino, nvmax=12)\nsumario.reg1 <- summary(ajusreg.comp1)\n## Os modelos vão ser escolhidos com base no menor BIC\nplot(sumario.reg1$bic,xlab=\"Número de Variáveis\",ylab=\"BIC\")\nwhich.min(sumario.reg1$bic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10\n```\n:::\n\n```{.r .cell-code}\npoints(7,sumario.reg1$bic[7],pch=20,col=\"red\")\n```\n\n::: {.cell-output-display}\n![](Aula05B_files/figure-html/BIC-1.png){width=90%}\n:::\n\n```{.r .cell-code}\ncoef(ajusreg.comp1,7) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n (Intercept)         chas          nox           rm          dis      ptratio \n 25.96604797   3.42886978 -14.98978400   4.52236738  -1.11439903  -0.90562812 \n       black        lstat \n  0.01090072  -0.52724645 \n```\n:::\n\n```{.r .cell-code}\noutro_mod1 <- lm(medv ~ chas + nox + rm + dis + ptratio + black + lstat, data=conj_treino)\nsummary(outro_mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = medv ~ chas + nox + rm + dis + ptratio + black + \n    lstat, data = conj_treino)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.0981  -2.7485  -0.7203   1.7972  28.4204 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  25.966048   5.285724   4.912 1.26e-06 ***\nchas          3.428870   0.964039   3.557 0.000416 ***\nnox         -14.989784   3.467498  -4.323 1.90e-05 ***\nrm            4.522367   0.435459  10.385  < 2e-16 ***\ndis          -1.114399   0.175406  -6.353 5.21e-10 ***\nptratio      -0.905628   0.118527  -7.641 1.33e-13 ***\nblack         0.010901   0.002722   4.005 7.26e-05 ***\nlstat        -0.527246   0.050937 -10.351  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.881 on 446 degrees of freedom\nMultiple R-squared:  0.7258,\tAdjusted R-squared:  0.7215 \nF-statistic: 168.7 on 7 and 446 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nsqrt(mean((conj_teste$medv - predict(outro_mod1, conj_teste)) ^ 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.96868\n```\n:::\n:::\n",
    "supporting": [
      "Aula05B_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}